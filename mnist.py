import numpy as np

def relu(x):
    return np.maximum(0,x)

def Convolution(input,kernel, bias):
    num_channel, num_input, input_width, input_height = input.shape
    num_filter, input_node, kernel_width, kernel_height = kernel.shape
    new_width = input_width - kernel_width + 1
    new_height = input_height - kernel_height + 1
    new_kernel = []
    for i in range(num_filter):
        for j in range(input_node):
            for k in range(kernel_width):
                for l in range(kernel_height):
                    new_kernel.append(kernel[i][j][k][l])
    new_kernel = np.array(new_kernel).reshape(num_filter, input_node, kernel_width, kernel_height)

    conv_sum = []
    if input_node == 1:
        for i in range(num_filter):
            for j in range(input_node):
                conv = []
                for k in range(new_height):
                    for l in range(new_width):
                        conv.append((input[0, j, k:k + kernel_height, l:l + kernel_width] * new_kernel[i][j]).sum())
                conv_sum.append(conv)

        conv_sum = np.array(conv_sum).reshape(num_channel, num_filter, new_width, new_height)

        #bias
        for i in range(num_channel):
            for j in range(num_filter):
                for k in range(new_width):
                    for l in range(new_height):
                        conv_sum[i][j][k][l] += bias[j]

        #conv_sum = relu(conv_sum)
        print('--------------------------------conv1 layer------------------------------------')
        print(conv_sum.shape)
        #print(conv_sum)

        return conv_sum

    elif input_node > 1:
        for i in range(num_filter):
            for j in range(input_node):
                conv = []
                for k in range(new_height):
                    for l in range(new_width):
                        conv.append((input[0, j, k:k + kernel_height, l:l + kernel_width] * new_kernel[i][j]).sum())
                conv_sum.append(conv)

        conv_sum = np.array(conv_sum).reshape(num_filter,input_node,new_width * new_height)
        filter_sum = 0
        all_filter_sum = []
        for i in range(num_filter):
            for j in range(new_width * new_height):
                for k in range(input_node):
                    filter_sum += conv_sum[i][k][j]
                all_filter_sum.append(filter_sum)
                filter_sum = 0

        all_filter_sum = np.array(all_filter_sum).reshape(num_channel, num_filter, new_width, new_height)

        #bias
        for i in range(num_channel):
            for j in range(num_filter):
                for k in range(new_width):
                    for l in range(new_height):
                        all_filter_sum[i][j][k][l] += bias[j]

        #all_filter_sum = relu(all_filter_sum)
        print('--------------------------------conv2 layer------------------------------------')
        print(all_filter_sum.shape)
        #print(all_filter_sum)

        return all_filter_sum

def Max_pooling(input,kernel_size):
    num_channel, num_input, input_width, input_height = input.shape
    input = relu(input)
    pool = []
    all_value = []
    for i in range(num_channel):
        for j in range(num_input):
            for k in range(0, input_width, kernel_size[0]):
                 for l in range(0, input_height, kernel_size[1]):
                    for m in range(kernel_size[0]):
                        for n in range(kernel_size[1]):
                            value = input[i][j][k + m][l + n]
                            all_value.append(value)
                    value_max = max(all_value)
                    pool.append(value_max)
                    all_value.clear()  # all_value reset

    new_width = int(input_width/kernel_size[0])
    new_height = int(input_height/kernel_size[1])
    pool = np.array(pool).reshape(num_channel, num_input, new_width, new_height)
    print('--------------------------------pool layer-------------------------------------')
    print(pool.shape)
    #print(pool)

    return pool

def Fully_connected(input, kernel, bias):
    num_channel, num_input, input_width, input_height = input.shape
    num_output, input_node = kernel.shape
    flatten = input.reshape(num_channel * num_input * input_width * input_height)
    print('---------------------------------flatten---------------------------------------')
    print(flatten.shape)
    #print(flatten)
    final_output = []
    for i in range(num_output):
        final_output.append((flatten * kernel[i]).sum())

    #bias
    for i in range(num_output):
        final_output[i] += bias[i]
    print('-------------------------------final output------------------------------------')
    final_output = np.array(final_output)
    print(final_output.shape)
    print(final_output)

    return final_output

test_data = np.loadtxt('test.csv', delimiter=',', dtype=np.float32)
test_data = test_data / 255
reshape_test_data = test_data[1:].reshape(1,1,28,28)
np.set_printoptions(threshold=np.inf) # 모든 배열의 수 출력

# (6,1,5,5)
Conv1_kernel = [[[[-0.0973, -0.1448,  0.1202,  0.1041,  0.0105],
          [ 0.1451,  0.1959,  0.0974, -0.0086,  0.1892],
          [ 0.1008,  0.0662,  0.0382, -0.1539, -0.0990],
          [ 0.1904, -0.1125, -0.0974,  0.0716,  0.1801],
          [ 0.1909, -0.1197, -0.0573, -0.1400,  0.0859]]],

        [[[ 0.0622,  0.0484,  0.1657,  0.1568,  0.1246],
          [ 0.1864,  0.1615,  0.0058, -0.1723,  0.1562],
          [ 0.1401, -0.1191, -0.1864, -0.1339, -0.1721],
          [ 0.1594, -0.1886,  0.1534,  0.0179,  0.1585],
          [-0.0430, -0.0963,  0.0006, -0.0216,  0.1036]]],

        [[[ 0.0038, -0.1456,  0.1182, -0.1542, -0.1925],
          [ 0.1396,  0.0114, -0.1804,  0.0953, -0.0943],
          [-0.1281, -0.0623, -0.1284,  0.0180, -0.0805],
          [-0.1488, -0.0760,  0.1848,  0.1051, -0.1952],
          [-0.0631, -0.0868, -0.1874, -0.0755,  0.0928]]],

        [[[-0.1351,  0.1135, -0.1180, -0.0594, -0.1530],
          [ 0.1624,  0.1698, -0.0846, -0.1876,  0.0391],
          [ 0.0935,  0.0438,  0.0033,  0.0450,  0.0736],
          [ 0.0884,  0.1547,  0.1378,  0.1748, -0.0623],
          [ 0.0459, -0.1455, -0.0238, -0.0570, -0.0264]]],

        [[[ 0.1763, -0.0393,  0.1811,  0.0362,  0.1609],
          [-0.0479, -0.1088,  0.1629, -0.0234,  0.1103],
          [ 0.0573, -0.0381, -0.0766,  0.0503, -0.1321],
          [ 0.0622,  0.0263, -0.0995,  0.0211, -0.0983],
          [-0.1802, -0.0504,  0.1063, -0.0577,  0.1350]]],

        [[[-0.0350,  0.0949, -0.1816, -0.1499, -0.0314],
          [-0.1042,  0.0698, -0.0684, -0.0791,  0.1051],
          [ 0.1968,  0.0651,  0.1861,  0.1495,  0.0522],
          [-0.0205,  0.0065, -0.0189,  0.1232,  0.0035],
          [-0.0973,  0.0852, -0.1648, -0.1952, -0.0840]]]]
Conv1_kernel_bias = [-0.0226,  0.0278,  0.1511, -0.1875, -0.0955,  0.1878]
Conv1_kernel = np.array(Conv1_kernel)
Pool1_kernel_filter_size = (2,2)    # 2*2 down sampling


# (3,6,5,5)
Conv2_kernel = [[[[ 0.0082, -0.0519, -0.0642, -0.0134,  0.0515],
          [ 0.0693,  0.0465, -0.0727,  0.0225, -0.0137],
          [-0.0672, -0.0799,  0.0267,  0.0117, -0.0760],
          [ 0.0571,  0.0745,  0.0290, -0.0246,  0.0564],
          [-0.0641,  0.0197, -0.0601,  0.0399, -0.0249]],

         [[ 0.0373,  0.0236,  0.0716, -0.0032,  0.0140],
          [-0.0045, -0.0477,  0.0155,  0.0408, -0.0045],
          [-0.0178,  0.0360,  0.0095, -0.0263,  0.0107],
          [-0.0217,  0.0536, -0.0573,  0.0760,  0.0147],
          [-0.0719, -0.0348, -0.0667,  0.0697, -0.0627]],

         [[ 0.0401,  0.0165, -0.0327, -0.0309, -0.0658],
          [ 0.0315,  0.0692, -0.0122,  0.0147, -0.0075],
          [-0.0188, -0.0343,  0.0376,  0.0617,  0.0091],
          [-0.0238,  0.0472, -0.0041,  0.0492,  0.0515],
          [ 0.0669, -0.0091,  0.0034,  0.0279, -0.0166]],

         [[-0.0237,  0.0023,  0.0323,  0.0761, -0.0792],
          [ 0.0812, -0.0517,  0.0339, -0.0738,  0.0530],
          [ 0.0670,  0.0502,  0.0188, -0.0215, -0.0804],
          [ 0.0492,  0.0440, -0.0459,  0.0209,  0.0473],
          [ 0.0047,  0.0517, -0.0194,  0.0542, -0.0027]],

         [[ 0.0364, -0.0010,  0.0556,  0.0472,  0.0661],
          [-0.0121, -0.0306,  0.0077, -0.0338, -0.0761],
          [ 0.0302,  0.0519, -0.0296, -0.0711, -0.0006],
          [-0.0467, -0.0574,  0.0703, -0.0311,  0.0094],
          [ 0.0642,  0.0535, -0.0520, -0.0727,  0.0397]],

         [[-0.0325,  0.0066,  0.0558, -0.0435, -0.0668],
          [-0.0707, -0.0684,  0.0744,  0.0465, -0.0672],
          [ 0.0601, -0.0559, -0.0244,  0.0702, -0.0400],
          [-0.0659,  0.0196,  0.0268,  0.0153, -0.0275],
          [ 0.0271,  0.0324, -0.0770,  0.0536, -0.0079]]],


        [[[ 0.0332,  0.0128,  0.0417,  0.0677, -0.0057],
          [ 0.0185,  0.0689,  0.0143, -0.0145,  0.0150],
          [-0.0532,  0.0172, -0.0571, -0.0474, -0.0241],
          [ 0.0222,  0.0011,  0.0071, -0.0647,  0.0737],
          [ 0.0498, -0.0105, -0.0222,  0.0153, -0.0239]],

         [[ 0.0370, -0.0369,  0.0035,  0.0760, -0.0561],
          [-0.0738,  0.0348,  0.0664,  0.0050, -0.0811],
          [ 0.0741, -0.0240,  0.0653, -0.0793, -0.0304],
          [-0.0094,  0.0214,  0.0337,  0.0330, -0.0153],
          [ 0.0337,  0.0779,  0.0434,  0.0138,  0.0308]],

         [[ 0.0466,  0.0478, -0.0498, -0.0624, -0.0481],
          [ 0.0796, -0.0153,  0.0385,  0.0327, -0.0677],
          [ 0.0273, -0.0315, -0.0440, -0.0489,  0.0512],
          [ 0.0339, -0.0510, -0.0415, -0.0011,  0.0718],
          [ 0.0136, -0.0605,  0.0058,  0.0731,  0.0702]],

         [[-0.0740,  0.0779, -0.0515,  0.0434, -0.0232],
          [ 0.0208, -0.0796,  0.0246, -0.0578, -0.0683],
          [ 0.0355,  0.0351,  0.0675,  0.0156,  0.0324],
          [ 0.0732,  0.0121, -0.0078, -0.0262, -0.0219],
          [ 0.0203,  0.0144, -0.0148,  0.0262,  0.0795]],

         [[-0.0420, -0.0073, -0.0520,  0.0289, -0.0511],
          [ 0.0022,  0.0722, -0.0732, -0.0571, -0.0811],
          [-0.0136,  0.0410,  0.0161, -0.0383,  0.0594],
          [-0.0192,  0.0340,  0.0707, -0.0197, -0.0355],
          [ 0.0741,  0.0290, -0.0409, -0.0342,  0.0549]],

         [[ 0.0013, -0.0205,  0.0136,  0.0365, -0.0262],
          [-0.0737, -0.0554, -0.0758, -0.0352, -0.0081],
          [-0.0012,  0.0029,  0.0290,  0.0326, -0.0028],
          [-0.0290,  0.0102,  0.0728, -0.0541, -0.0591],
          [-0.0305, -0.0741, -0.0393,  0.0042,  0.0663]]],


        [[[-0.0495,  0.0140, -0.0118, -0.0174,  0.0308],
          [-0.0551, -0.0636, -0.0480,  0.0257,  0.0023],
          [ 0.0477,  0.0764,  0.0810, -0.0050,  0.0682],
          [ 0.0063,  0.0581, -0.0757,  0.0479,  0.0525],
          [ 0.0598,  0.0324,  0.0098,  0.0257,  0.0526]],

         [[-0.0158, -0.0369, -0.0449,  0.0176, -0.0679],
          [-0.0113,  0.0317, -0.0673, -0.0157, -0.0360],
          [ 0.0805,  0.0423, -0.0004, -0.0676,  0.0424],
          [ 0.0387, -0.0282, -0.0147, -0.0774, -0.0592],
          [ 0.0699, -0.0645, -0.0791,  0.0454,  0.0153]],

         [[-0.0042,  0.0579,  0.0775, -0.0215, -0.0699],
          [ 0.0676,  0.0165,  0.0268, -0.0782,  0.0205],
          [-0.0506,  0.0292,  0.0372, -0.0655,  0.0087],
          [-0.0205, -0.0784,  0.0423, -0.0548,  0.0032],
          [-0.0582, -0.0304,  0.0804, -0.0356,  0.0302]],

         [[ 0.0743, -0.0759,  0.0064,  0.0031, -0.0757],
          [-0.0622,  0.0638,  0.0688,  0.0449, -0.0457],
          [ 0.0282,  0.0672, -0.0243,  0.0004,  0.0685],
          [ 0.0101, -0.0140,  0.0285, -0.0039, -0.0051],
          [-0.0684, -0.0801,  0.0657, -0.0141,  0.0618]],

         [[ 0.0764,  0.0466, -0.0413,  0.0269,  0.0050],
          [-0.0660, -0.0628,  0.0416,  0.0223,  0.0717],
          [ 0.0763, -0.0739, -0.0240,  0.0115, -0.0413],
          [-0.0366,  0.0066, -0.0557,  0.0587, -0.0268],
          [ 0.0719, -0.0096,  0.0047, -0.0344,  0.0462]],

         [[ 0.0632, -0.0090,  0.0167,  0.0422,  0.0456],
          [-0.0498, -0.0803, -0.0554, -0.0437,  0.0515],
          [-0.0728,  0.0266, -0.0674, -0.0473,  0.0560],
          [-0.0170, -0.0572, -0.0478, -0.0675,  0.0467],
          [ 0.0716, -0.0238, -0.0659,  0.0076,  0.0312]]]]
Conv2_kernel_bias = [-0.0061,  0.0448,  0.0293]
Conv2_kernel = np.array(Conv2_kernel)
Pool2_kernel_filter_size = (2,2)                                                                                                # 2*2 down sampling

# (10,48)
fc1_kernel = [[-0.1286,  0.1005, -0.0100, -0.1277, -0.0308, -0.0695,  0.0207,  0.0603,
          0.0437, -0.1260,  0.1295,  0.0226, -0.1277,  0.0424, -0.0922,  0.0515,
         -0.0441, -0.0676, -0.0958, -0.0582, -0.1353,  0.1059,  0.1268, -0.0641,
         -0.1260,  0.1390,  0.0856, -0.1096, -0.0447,  0.1147, -0.1038,  0.0190,
         -0.0923, -0.0447,  0.0971,  0.1310, -0.0838,  0.0961,  0.1378, -0.0860,
          0.0933, -0.0990,  0.0930,  0.0662, -0.0155, -0.0927,  0.0325,  0.1281],
        [ 0.0366,  0.0933,  0.0852, -0.1126,  0.0098,  0.1396,  0.1102, -0.1425,
          0.0982,  0.0475,  0.1255,  0.0085,  0.1240, -0.0399, -0.0329, -0.1434,
         -0.1417,  0.1010, -0.0267,  0.0079, -0.0498,  0.0202,  0.0876, -0.1118,
          0.1351, -0.1402, -0.0330,  0.0995,  0.1102,  0.0688, -0.0574, -0.0204,
         -0.1201,  0.0499,  0.0156,  0.0367,  0.1067,  0.0388,  0.1151, -0.0710,
         -0.0237,  0.1022,  0.1348,  0.0342, -0.1110, -0.0712, -0.0218, -0.0286],
        [-0.1107, -0.0560, -0.0811,  0.0491, -0.0066, -0.0398, -0.0853,  0.1042,
         -0.0903,  0.1413, -0.0005,  0.0860, -0.0562, -0.0215,  0.0790,  0.0220,
         -0.0682, -0.1082, -0.1169, -0.0509,  0.1038, -0.1294,  0.1438,  0.1041,
         -0.1388,  0.1005,  0.1157,  0.0143, -0.1115,  0.1152,  0.1155,  0.1117,
         -0.1273,  0.0182, -0.1020, -0.1055,  0.1335,  0.1289,  0.1350, -0.0634,
          0.1205, -0.0529,  0.0770, -0.1088, -0.0631,  0.0312, -0.1107, -0.0854],
        [ 0.0953,  0.1093,  0.0152, -0.0705,  0.0922,  0.0394,  0.0569,  0.0643,
         -0.0591, -0.0923,  0.0358,  0.0276,  0.0809, -0.1350,  0.1082,  0.0497,
          0.0376, -0.0562, -0.0961, -0.0681,  0.0490, -0.0451,  0.0773, -0.0164,
         -0.0289, -0.0690,  0.0389,  0.0680,  0.0242,  0.0796, -0.0389, -0.0779,
          0.1314, -0.1069, -0.0648,  0.0748, -0.0245,  0.1127, -0.0368, -0.1066,
          0.1389,  0.1328, -0.0557,  0.0924, -0.1018, -0.0477,  0.1035,  0.0112],
        [ 0.1201, -0.1141,  0.1222,  0.1353,  0.0687,  0.1425, -0.1123, -0.0156,
         -0.0252,  0.1051,  0.1073,  0.1006,  0.0174,  0.0683, -0.1389, -0.1245,
         -0.0636,  0.1051,  0.1256, -0.0068,  0.1379,  0.0055, -0.1257, -0.1205,
          0.1327,  0.0886,  0.0688, -0.0999,  0.1129, -0.0051,  0.0567,  0.1277,
          0.1411,  0.0926,  0.0270,  0.1398, -0.0938, -0.0405, -0.0896,  0.0623,
          0.1198, -0.1023, -0.0685, -0.1072, -0.1184,  0.0203, -0.1323, -0.1384],
        [ 0.1333, -0.1431, -0.0905, -0.0685, -0.0494,  0.1032,  0.0269,  0.0837,
         -0.1239, -0.0654,  0.0762, -0.0434,  0.0478,  0.0307,  0.1198, -0.1402,
          0.0848, -0.1028,  0.0427,  0.1356,  0.0494, -0.0623, -0.0107,  0.0054,
         -0.0534, -0.1076,  0.0313, -0.0238, -0.1085, -0.1439, -0.0495,  0.1346,
         -0.1368,  0.0676,  0.0401, -0.0021, -0.0777,  0.1248, -0.0911,  0.1394,
          0.1352,  0.1301, -0.1001, -0.0893,  0.1382, -0.0979,  0.0408, -0.0872],
        [ 0.0891,  0.0805, -0.1428,  0.0075,  0.0721, -0.0870, -0.1138,  0.1371,
         -0.0151, -0.0261, -0.0956,  0.0865,  0.0803, -0.0497, -0.1067, -0.1016,
          0.0079,  0.0468, -0.0262, -0.0208,  0.0518,  0.1126, -0.1010, -0.0564,
         -0.0318, -0.0041,  0.1368,  0.1432,  0.0697,  0.0521,  0.0528, -0.0939,
          0.0970,  0.1327,  0.0636, -0.0718,  0.1403, -0.0049,  0.1140, -0.1137,
         -0.0760,  0.1195,  0.0476,  0.0794, -0.0287, -0.1129,  0.0518,  0.0532],
        [-0.0596, -0.0759,  0.0464,  0.0728,  0.0501, -0.0599, -0.0193,  0.0535,
         -0.0799, -0.0345, -0.0169, -0.1357,  0.0643, -0.0579,  0.1313,  0.1053,
         -0.0921,  0.0279, -0.0556,  0.0247,  0.1042, -0.1140,  0.1161,  0.0670,
         -0.0650, -0.0157, -0.0467,  0.0838,  0.0741,  0.1199,  0.1359, -0.0570,
          0.0882, -0.1332, -0.0900,  0.0705, -0.1110, -0.0042, -0.0743, -0.1333,
          0.0875, -0.1315,  0.0111,  0.0676, -0.1057,  0.0331,  0.0618, -0.0340],
        [-0.0483,  0.1389, -0.0944, -0.1234, -0.0566, -0.0829,  0.0631, -0.0737,
          0.1298, -0.0738,  0.0841,  0.0139, -0.1100, -0.1068,  0.0705, -0.0480,
         -0.0657, -0.0974,  0.0892,  0.0164,  0.0436,  0.0619, -0.0154,  0.0934,
          0.1192, -0.0894, -0.1242, -0.1074,  0.0393, -0.0871, -0.0622, -0.0257,
         -0.0236,  0.0595,  0.0458,  0.0677, -0.1122,  0.0506,  0.0910, -0.0228,
          0.0031,  0.0634,  0.0276, -0.0797,  0.0135,  0.0996, -0.0366, -0.0893],
        [ 0.0757,  0.0366,  0.1146,  0.0855,  0.0813,  0.0194,  0.0265, -0.1197,
          0.0205, -0.1429, -0.0250,  0.0562, -0.1367, -0.1222,  0.0020, -0.0202,
         -0.0516, -0.0597,  0.0675, -0.1065,  0.0017,  0.1413,  0.1244, -0.0600,
          0.1077,  0.0267,  0.0669, -0.1246, -0.0396,  0.0527,  0.1432,  0.1116,
         -0.0297,  0.0585, -0.1340,  0.0406,  0.0144,  0.1265,  0.1049,  0.1127,
         -0.1142, -0.0398,  0.1182,  0.0910, -0.1045,  0.1167, -0.0895, -0.0432]]
fc1_bias = [ 0.0343, -0.1170, -0.0274,  0.0443, -0.0209,  0.1399,  0.0709, -0.0648, -0.0002, -0.0145]
fc1_kernel = np.array(fc1_kernel)


Conv1 = Convolution(reshape_test_data, Conv1_kernel, Conv1_kernel_bias)
Max_pooling1 = Max_pooling(Conv1, Pool1_kernel_filter_size)
Conv2 = Convolution(Max_pooling1, Conv2_kernel, Conv2_kernel_bias)
Max_pooling2= Max_pooling(Conv2, Pool2_kernel_filter_size)
fc1 = Fully_connected(Max_pooling2, fc1_kernel, fc1_bias)